---
title: "Modélisation statistique"
author: "Léo Belzile, HEC Montréal"
subtitle: "01. Inférence statistique"
date: today
date-format: YYYY
eval: true
cache: true
echo: true
lang: fr
standalone: true
bibliography: MATH60604A.bib
format:
  revealjs:
    slide-number: true
    preview-links: auto
    code-block-height: 750px
    theme: [simple, hecmontreal.scss]
    title-slide-attributes:
      data-background-color: "#002855"
    logo: "fig/logo_hec_montreal_bleu_web.png"
    width: 1600
    height: 900
---


```{r}
#| eval: true
#| include: false
#| cache: false
hecbleu <- c("#002855")
fcols <- c(gris = "#888b8d",
           bleu = "#0072ce",
           aqua = "#00aec7",
           vert = "#26d07c",
           rouge = "#ff585d",
           rose = "#eb6fbd",
           jaune = "#f3d03e")
pcols <- c(gris = "#d9d9d6",
           bleu = "#92c1e9",
           agua = "#88dbdf",
           vert = "#8fe2b0",
           rouge = "#ffb1bb",
           rose = "#eab8e4",
           jaune = "#f2f0a1")
library(ggplot2)
theme_set(theme_classic())
library(patchwork)
knitr::opts_chunk$set(fig.retina = 3, collapse = TRUE)
options(digits = 3, width = 75)
```


# Inférence statistique  {background-color="#002855"}


## Étude d'une population

La loi d'une population (qui décrit les valeurs possibles et leur fréquence/probabilité) contient toute l'information nécessaire.

```{r}
#| eval: true
#| echo: false
#| out-width: '70%'
set.seed(234)
prob <- c(1,2,3.4,5,8,4,2.3,5,4,2)
prob <- prob/sum(prob)
prob2 <- mev::rdir(n = 1, alpha = 3 + prob)[1,]
prob2 <- prob2/sum(prob2)
p1 <- ggplot(data = data.frame(x = 1:10, 
                         p = prob)) +
  geom_bar(mapping = aes(x = x, weight = p)) +
  scale_x_continuous(breaks = 1:10, labels = 1:10) +
  labs(subtitle = "contrôle",
       x = "",
       y = "probabilité") + 
  theme_classic()
p2 <- ggplot(data = data.frame(x = 1:10, 
                         p = prob2)) +
  geom_bar(mapping = aes(x = x, weight = p)) +
  scale_x_continuous(breaks = 1:10, labels = 1:10) +
  labs(subtitle = "traitement",
       y = "probabilité",
       x = "") +
  theme_classic()
library(patchwork)
  p1 + p2
```



## Variabilité échantillonale

```{r}
#| label: unifsamp1
#| cache: true
#| echo: false
#| fig-cap: Histogrammes de 10 échantillons aléatoires simples de taill 20 d'une loi uniforme.
#| fig-width: 8
#| fig-height: 4.5
#| out-width: 80%
set.seed(1234)
ng <- 10
ns <- 20
df <- data.frame(x = runif(ng*ns,1,10),
             sample=rep(1:ng,each=ns))
ggplot(df, aes(x = x, y = ..density..)) +
  geom_hline(yintercept = 0.1, col = "gray", lty = 2) +
  geom_histogram(bins=10, color="white",)+
  facet_wrap(~sample, nrow = 2)+
  labs(y = "", 
       subtitle = "proportion échantillonnale dans le groupe traitement (haut) et contrôle (bas)", 
       x = "") +
  scale_x_continuous(breaks=c(0,5,10)) +
  theme_classic()
```

## Prise de décisions avec incertitude

La **statistique** traite de la prise de décisions dans un contexte d'incertitude.

- La collecte de données est coûteuse. 
    - nous avons une quantité d'information limitée sur la population.
    - on s'intéresse typiquement aux moments (moyenne théorique $\mu$, écart-type $\sigma$, etc.)
- Les échantillons sont typiquement trop petits pour estimer de manière fiable la loi de la population.
    - on se base plutôt sur un modèle statistique pour obtenir des informations.
 

## Pourquoi employer des modèles?

Ce cours traite de modélisation des données. Une citation célèbre attribuée à George Box dit que

> tous les modèles sont faux, mais certains sont utiles.

@McCullagh.Nelder:1989 expliquent dans le préambule de leur livre

> La modélisation en science demeure, du moins partiellement, un art. Certains principes existent, en revanche, pour guider le modélisateur. Le premier est que tous les modèles sont faux; mais que **certains sont meilleurs** et **le modélisateur doit chercher le meilleur à sa portée**. En même temps, il est sage de reconnaître que la quête perpétuelle de la vérité n’est pas envisageable.

## Plaidoyer pour la modélisation

Et David R. Cox de rajouter

> ...il n’est pas utile de simplement énoncer que tout modèle est faux. L’idée même de modèle sous-tend une notion de simplification et d’idéalisation. L’idée qu’un système physique, biologique ou sociologique complexe puisse être décrit de manière exacte par quelques formules est franchement absurde. La construction de **représentations idéalisées qui capturent les aspects stables les plus importants du système** est néanmoins une partie essentielle de toute analyse scientifique et les modèles statistiques ne diffèrent pas en cela d’autres types de modèles.

## Quels sont les éléments d'un modèle

Un modèle stochastique (ou aléatoire) combine typiquement

- une loi pour les données avec
- une formule liant les paramètres ou la moyenne conditionnelle d'une variable réponse $Y$ à des variables explicatives $\mathbf{X}$

Les modèles sont des "golems" qui servent à obtenir des réponses à nos questions.

## Comment modéliser

0. Déterminer notre question de recherche et collecter des données.
1. Effectuer une analyse exploratoire.
    - quels sont les faits saillants à prendre en considération?
2. Construire un modèle préliminaire.
3. Vérifier la qualité de l'ajustement.
4. Recommencer et itérer au besoin.

## Comment déterminer le modèle adéquat?

On se base notamment sur les informations suivantes

1. plan de collecte de données
   - quel est le méchanisme pour l'échantillonage?
   - est-ce que les variables sont observées ou manipulées dans le cadre d'une expérience?
2. la nature de la variable réponse
   - décomptes, proportions, etc.

## Nature des données

- Est-ce que les données forment un **échantillon aléatoire simple** ou pas?
   - si oui, elles sont représentatives et on peut généraliser les conclusions à toute la population
- Est-ce que le "traitement" est assigné de manière aléatoire?
   - si oui, on parle de données expérimentales (plutôt qu'observationnelles).

```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
#| fig-align: "center"
knitr::include_graphics("fig/01/random_sample_assignment.png")
```


## Observationel versus expérimental

Sans ajustement supplémentaire, on ne peut tirer de conclusions ou d'énoncés de cause à effet avec des données observationnelles.

```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
#| fig-align: "center"
knitr::include_graphics("fig/01/nyt-wellness-program.png")
```


# Exemples de modélisation {background-color="#002855"}

## 1. Examens de conduite en Grande-Bretagne {.smaller}

Est-ce que les examens pratiques de conduite en Grande-Bretagne sont plus faciles dans les régions à faible densité de population? Source: [The Guardian, August 23rd, 2019](https://www.theguardian.com/world/2019/aug/23/an-easy-ride-scottish-village-fuels-debate-driving-test-pass-rates)

:::: {.columns}

::: {.column width="50%"}
```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
knitr::include_graphics("fig/01/guardian_driving.png")
```

:::


::: {.column width="50%"}
```{r}
#| eval: true
#| echo: false
#| out-width: '80%'
knitr::include_graphics("fig/01/guardian_driving_infographic.png")
```

:::

::::

Modèle: régression binomiale logistique. Données `gbconduite`, paquet **R** `hecmodstat`.



<!--
## Motivating examples - smartwatches are distracting.

Eye tracking gaze distribution results show that participants were more distracted in the smartwatch condition than in the mobile phone condition, they were less distracted in the speaker condition than in the phone condition, and they were more distracted in the texting condition than in any of the others.
-->

## 2. Sécurité routière et distraction dues aux montres intelligentes {.smaller}

:::: {.columns}

::: {.column width="50%"}
```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
knitr::include_graphics("fig/01/smartwatches.png")
```


Modèle: Analyse de variance pour données répétées, ou tests nonparamétrique de Friedman. Données `BRLS21_T3`, paquet `hecedsm`.

:::


::: {.column width="50%"}

@Brodeur:2021

> Une expérience intra-sujet a été menée dans un simulateur de conduite où 31 participants ont reçu des messages textuels et y ont répondu sous quatre scénarios: ils ont reçu des notifications (1) sur un téléphone portable, (2) sur une montre intelligente et (3) sur un haut-parleur, puis ont répondu oralement à ces messages. Ils ont également (4) reçu des messages textes où ils devaient répondre par texte aux notifications. 


:::

::::

## 3. Perception environnemental des emballages plastiques {.smaller}

:::: {.columns}

::: {.column width="50%"}
```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
knitr::include_graphics("fig/01/package-paper-plastic.png")
```

:::


::: {.column width="40%"}
@Sokolova:2023

> Huit études documentent le biais de perception du respect de l'environnement selon lequel les consommateurs jugent les emballages en plastique enrobés d'un emballage carton superflu plus respectueux de l'environnement que les emballages en plastique identiques sans carton.

:::

::::

Modèle: régression linéaire avec contrastes. Données `SKD23_S2A`, paquet `hecedsm`

## 4. Tests A/B et titres des nouvelles {.smaller}


:::: {.columns}

::: {.column width="60%"}
```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
knitr::include_graphics("fig/01/upworthy.png")
```

:::


::: {.column width="40%"}
Upworthy.com, un éditeur de médias américain, a révolutionné la publicité en ligne en effectuant des tests A/B systématiques pour comparer les différentes formulations des titres, l'emplacement du texte et de l'image afin de déterminer ce qui attire le plus l'attention. 

Les archives de recherche d'Upworthy [@Matias:2021] contiennent les résultats de 22743 expériences, avec un taux moyens de clics de 1.58% (écart type de 1.23%).

:::

::::

Modèle: régression Poisson avec décalage. Données `upworthy_sesame`, paquet `hecbayes`.




## 5. Impact de la visioconférence sur la créativité {.smaller}




:::: {.columns}

::: {.column width="40%"}
```{r}
#| eval: true
#| echo: false
#| out-width: '80%'
knitr::include_graphics("fig/01/Brucks_Levav-virtual_communications.png")
```

:::


::: {.column width="60%"}

@Brucks.Levav:2022

> Dans une étude en laboratoire et une expérience sur le terrain dans cinq pays (en Europe, au Moyen-Orient et en Asie du Sud), nous montrons que la vidéoconférence inhibe la production d'idées créatives [...]  

> Nous démontrons que la vidéoconférence entrave la production d'idées parce que les communicants se concentrent sur l'écran, ce qui incite à une focalisation cognitive plus étroite. Nos résultats suggèrent que l'interaction virtuelle a un coût cognitif pour la génération d'idées créatives.


:::

::::

- Modèle 1: régression linéaire avec matrice d'équicorrélation/MANOVA. Données `BL22_E`, paquet `hecedsm`
- Modèle 2: régression binomiale. Données `BL22_L`, paquet `hecedsm`.

## 6. Suggestion des montants pour les dons de charité {.smaller}


:::: {.columns}

::: {.column width="50%"}

@Moon.VanEpps:2023

> Dans sept études, nous démontrons que les suggestions de montants, où on propose des choix multiples sur le montant à donner (par exemple, 5$, 10$ ou 15$), augmentent les contributions par rapport aux contributions libres. 


> Nos résultats offrent de nouvelles perspectives conceptuelles sur la façon dont ces propositions augmentent les contributions, ainsi que des implications pratiques pour les organisations caritatives afin d'optimiser les contributions.
:::

::: {.column width="50%"}

```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
knitr::include_graphics("fig/01/Moon_VanEpps-giving.png")
```

:::

::::

Modèle: régression Tobit de type II, régression Poisson. Données `MV23_S1` du paquet `hecedsm`.

## 7. Décisions intégrées dans l'achat en ligne {.smaller}

:::: {.columns}

::: {.column width="60%"}

@Duke.Amir:2023

> Les clients doivent souvent décider de la quantité à acheter. La présente étude présente et compare le format de vente quantitatif-séquentiel, dans lequel les acheteurs prennent séparément les décisions d'achat et de quantité, avec le format de vente quantitatif-intégré, dans lequel les acheteurs prennent simultanément la décision d'acheter ou non et la quantité à acheter. Bien que les détaillants utilisent souvent le format séquentiel, nous démontrons que le format intégré peut augmenter les ventes.



> Une expérience sur le terrain menée auprès d'une grande entreprise technologique a montré que l'intégration des quantités permettait d'augmenter considérablement les ventes, de plus d'un million de dollars par an. 


:::

::: {.column width="40%"}

```{r}
#| eval: true
#| echo: false
#| out-width: '100%'
knitr::include_graphics("fig/01/Duke_Amir.png")
```


Modèle: régression logistique. Données `DA23_E1`, paquet `hecedsm`
:::

::::

## 8. Prix de l'essence en Gaspésie {.smaller}



:::: {.columns}

::: {.column width="50%"}

Des maires ont demandé à la [**Régie de l'énergie**](https://www.regie-energie.qc.ca/fr) d'enquête sur un possible cartel de l'essence en Gaspésie, où les prix au détail étaient anormalement élevés. Le rapport a conclu que les prix étaient plus élevés qu'attendu, mais que le nombre de détaillants par capita était plus élevé, ce qui réduisait les volumes de ventes et pouvait expliquer l'augmentation des marges observées.

Source: Radio-Canada [1](https://ici.radio-canada.ca/nouvelle/1303956/prix-essence-gaspe-enquete), [2](https://ici.radio-canada.ca/nouvelle/1463520/prix-essence-gaspesie-rapport-regie-energie)
:::

::: {.column width="50%"}

```{r}
#| eval: true
#| echo: false
#| out-width: '90%'
knitr::include_graphics("fig/01/regieenergie.png")
```

:::

::::

Modèle: régression linéaire avec erreurs autorégressives. Données `renergie`, paquet `hecmodstat`.


# Tests d'hypothèse {background-color="#002855"}


## Variabilité échantillonale

On ne peut comparer des statistiques sans prendre en compte l'incertitude inhérente due à la leur estimation à l'aide d'un échantillon aléatoire.

```{r}
#| label: fig-samplevar
#| eval: true
#| echo: false
#| fig-cap: Cinq échantillons de taille 10 tirés d'une même population de moyenne $\mu$
#|   (ligne horizontale). Les segments colorés donnent les moyennes des sous-groupes.
set.seed(1234)
samp <- data.frame(dat = rgamma(50, shape = 10, rate = 2),
                   group = factor(rep(1:5, each = 10L)))
ggplot(data = samp,
       aes(x = group, y = dat, col = group)) +
  geom_hline(yintercept = 5) +
  geom_point() +
  geom_jitter() +
  labs(col = "échantillon", y = "observations", x = "numéro d'échantillon") +
  stat_summary(fun = mean,
               geom = "point",
               shape = 95,
               size = 20) +
  theme_classic() +
  theme(legend.position = "none")
```


## Le signal et le bruit

Plus le rapport signal/bruit est important, plus notre capacité à détecter des différences existantes est grande.

```{r}
#| label: plots
#| echo: false
#| fig-height: 4
#| fig-width: 8
#| out-width: 80%
set.seed(12345)
dat1 <- data.frame(dat = rnorm(100, mean = 10, sd = 3) + rep((1:4)/4, each = 25),
       group = factor(x = rep(1:4, each = 25), 
                      labels = letters[1:4]))

g1 <- ggplot(dat = dat1, aes(x = group, 
                       y = dat, 
                       col = group)) +
  geom_boxplot() +
  geom_jitter(width = 0.3) +
  labs(y = "observations",
         subtitle = "signal faible, bruit fort") +
  theme_bw() +
  theme(legend.position = "none")

dat2 <- data.frame(dat = rnorm(100, mean = 10, sd = 0.5) + rep((1:4)[sample.int(4,4)], each = 25),
       group = factor(x = rep(1:4, each = 25), 
                      labels = letters[1:4]))

g2 <- ggplot(dat = dat2, aes(x = group, 
                       y = dat, 
                       col = group)) +
  geom_boxplot() +
  geom_jitter(width = 0.3) +
  labs(y = "observations",
         subtitle = "signal fort, bruit faible") +
  theme_bw() +
  theme(legend.position = "none")
g1 + g2 
```


---

## Accumulation de l'information

À mesure que l'on collecte plus d'observations et que la taille de l'échantillon augmente, on peut mieux discriminer.


```{r}
#| label: fig-uniformsamp2
#| fig-cap: Histogrammes de données tirées d'une loi uniforme (haut) et d'une loi non-uniforme (bas) pour des tailles d'échantillons de 10, 100, 1000 and 10 000 (de gauche à droite).
#| echo: false
#| eval: true
set.seed(1234)
ntot <- (10+100+1000+10000)
df <- data.frame(
  x = c(sample.int(n = 10,
                   size = ntot,
                   replace = TRUE),
        round(TruncatedNormal::rtnorm(n = ntot,
                                      sd = 4,
                                      mu = 6,
                                      lb = 1,
                                      ub = 10))),
  group = rep(factor(c("null","alternative")),
              each = ntot),
  sample = rep(factor(c(rep(1,10),
                    rep(2,100),
                    rep(3, 1000),
                    rep(4, 1e4)),
                    labels = c("10","100","1000","10 000")), length.out = 2*ntot))
g1 <- ggplot(df |> dplyr::filter(group == "alternative"), aes(x = x, y = after_stat(density))) +
  geom_hline(yintercept = 0.1, col = "gray", lty = 2) +
  geom_histogram(bins = 10, color="white", fill = 2)+
  facet_wrap(~sample, nrow = 1,
             labeller = label_wrap_gen(multi_line=FALSE))+
  labs(y = "proportion", x = "") +
  scale_x_continuous(breaks=c(0,5,10)) +
  theme_classic()
g2 <- ggplot(df |> dplyr::filter(group == "null"), aes(x = x, y = after_stat(density))) +
  geom_hline(yintercept = 0.1, col = "gray", lty = 2) +
  geom_histogram(bins = 10, color="white", fill = 4)+
  facet_wrap(~sample, nrow = 1,
             labeller = label_wrap_gen(multi_line=FALSE))+
  labs(y = "proportion", x = "") +
  scale_x_continuous(breaks=c(0,5,10)) +
  theme_classic()
g2 / g1
```


## Recette pour les tests d'hypothèses

Un test d'hypothèse est une règle de décision binaire (rejetter ou ne pas rejetter)

Voici les étapes de la démarche.

1. définir les paramètres du modèle,
2. formuler les hypothèses alternative et nulle,
3. choisir et calculer la statistique de test,
4. déterminer son comportement sous $\mathscr{H}_0$ (loi nulle),
5. calculer la valeur-*p*,
6. conclure dans le contexte du problème.



## Exemple: texter en marchant

Le centre de recherche en expérience utilisateur de HEC Montréal, le Tech3Lab, a effectué une étude sur la distraction causée le fait de texter en marchant.

```{r}
#| label: tech3lab
#| echo: false
#| out-width: '65%'
#| fig-align: 'center'
knitr::include_graphics('fig/01/Tech3Lab-texter.jpg')
```

## Détails de l'étude

- 35 sujets ont participé à l'étude.
- Chaque personne devait marcher sur un tapis roulant et un écran projetait des obstacles.
- Au cours d'une séance, le sujet marchait en parlant au cellulaire tandis que lors d'une autre séance, il devait marcher en textant.
- L'ordre entre les séances a été déterminé au hasard.
- Différents obstacles étaient présentés durant une séance selon un ordre aléatoire.
- Nous allons nous intéresser à l'un d'eux, l'apparition d'un cycliste dans le champ visuel

## Caractéristiques

- Population: adultes (18 ans et plus)
- Échantillon: 35 individus
- Variables:
    - temps pour percevoir un obstacle: quantitatif
    - type de distraction (cellulaire ou textos): nominale

On s'intéresse au temps (en secondes) que prend une personne pour apercevoir cet obstacle (mesuré à l'aide d'un encéphalogramme).


## 1.  Définir les variables d'intérêt

- $\mu_{\texttt{c}}$: moyenne du temps de réaction (en secondes) lors d'un appel (`c`)
- $\mu_{\texttt{t}}$: moyenne du temps de réaction (en secondes) lorsqu'on texte (`t`)



## 2. Formuler les hypothèses alternatives et nulles

- Hypothèse d'intérêt: est-ce que texter est plus distrayant?
    - $\mathscr{H}_a: \mu_{\texttt{t}} > \mu_{\texttt{c}}$ (unilatéral)
- Hypothèse nulle (avocat du Diable)
    - $\mathscr{H}_0: \mu_{\texttt{t}} \leq  \mu_{\texttt{c}}$

On exprime l'hypothèse en fonction de la différence: 
\begin{align*}
\mathscr{H}_a: \mu_{\texttt{t}} - \mu_{\texttt{c}}>0.
\end{align*}


On ne va juger la preuve contre l'hypothèse nulle qu'à une seule valeur numérique.

## Comment déterminer le fardeau de la preuve?


- Une **statistique** est une fonction des données qui retourne un résumé numérique. 
- Il existe des principes généraux pour la construction de statistiques: par exemple, les **statistiques de Wald** sont de la forme
\begin{align*}
W = \frac{\text{qté estimée} - \text{qté postulé}}{\text{erreur-type (qté estimée)}} = \frac{T - T_0}{\mathsf{se}(T)}
\end{align*}
    - Les statistiques n'ont pas d'unité.
    - Elles sont standardisées `pourà des fins d'étalonnage.
    - L'**erreur-type** mesure l'incertitude de la statistique

 
::: aside
Ne pas mélanger erreur-type (variabilité d'une statistique) et écart-type (terme réservé à la variabilité d'une unité de la population)
:::

## 3. Choisir la statistique de test

On s'intéresse à la différence de temps de réaction (moyenne)

- Test-_t_ pour un échantillon pour $\texttt{t}-\texttt{c}$ (un test-_t_ pour données appariées) 
\begin{align*}
T_D=\frac{\overline{D}-\mu_0}{\mathsf{se}(\overline{D})}
\end{align*}
- $\overline{D}$ est la différence des temps moyens de réaction.
- On postule $\mu_0=\mu_{\texttt{t}}-\mu_{\texttt{c}}=0$.
- L'erreur-type de $\overline{D}$ est $\mathsf{se}(\overline{D})=S_D/\sqrt{n}$, où $S_D$ est l'écart-type des variables $D_i$ et $n$ est la taille de l'échantillon.

## Code **R**

```{r}
#| label: distraction_code
#| eval: true
#| echo: true
data(distraction, package = "hecmodstat")
ttest <- with(distraction,
     t.test(x = t,
            y = c, 
            paired = TRUE, 
            alternative = "greater"))
```


```{r}
#| label: distraction-output
#| eval: true
#| echo: false
ttest
```

## Loi nulle

La loi nulle nous renseigne sur les valeurs plausibles de la statistique si l'hypothèse nulle tient la route, et leurs fréquence ou probabilité relative.

- On se base typiquement sur une approximation asymptotique (grands échantillons), qui est justifiée par le théorème central limite.
- Sinon, on peut utiliser l'inférence par simulations (par exemple, un [test de permutation](https://www.jwilber.me/permutationtest/)).
- La loi nulle est notre étalon de mesure pour déterminer si la valeur observée de la statistique est extrême.

## Lois nulles



```{r}
#| label: fig-renfepermut
#| cache: true
#| echo: false
#| fit.height: 5
#| fig-align: 'center'
#| fig-cap: Approximation normale (traitillé) et basée sur les permutations (ligne pleine) pour une statistique de test. La valeur de la statistique observée sur l'échantillon est représentée par une droite verticale.
#| fig-width: 6
# p-value (permutation test)
data(renfe, package = "hecstatmod")
# Sub-sample with only Promo tickets
renfe_promo <- renfe |>
   dplyr::filter(fare == "Promo",
                 type == "AVE")

# two-sample t-test and mean difference
ttest <- t.test(price~dest, data = renfe_promo)
n <- nrow(renfe_promo)
B <- 1e4
ttest_stats <- numeric(B)
ttest_stats[1] <- ttest$statistic
set.seed(20200608) # set seed of pseudo-random number generator
for(i in 2:B){
  # Recalculate the test statistic, permuting the labels
  ttest_stats[i] <- t.test(price ~ dest[sample.int(n = n)],
                           data = renfe_promo)$statistic
}
# Graphics library
library(ggplot2)
# Plot the empirical permutation distribution
ggplot(data = data.frame(statistic = ttest_stats),
       aes(x=statistic)) +
  geom_histogram(bins = 30, aes(y=after_stat(density)), alpha = 0.2) +
  geom_density() +
  geom_vline(xintercept = ttest_stats[1]) +
  scale_y_continuous(limits = c(0,NA), expand = expansion(mult = c(0,0.1))) + 
  labs(y = "densité", x = "statistique") +
  stat_function(fun = dnorm, linetype = "dashed")
```

## 4. Comparer la valeur numérique obtenue à la loi nulle

 

- La statistique vaut $t_D = 2.91$.
- On s'intéresse uniquement à la probabilité d'obtenir $T_D > 2.91$ sous $\mathscr{H}_0$ (test unilatéral).
- On utilise comme loi nulle une loi Student-_t_ standard avec 34 degrés de liberté, dénotée $T \sim \mathsf{Student}(34)$.
- Le $0.05$ quantile de $T$ est $\mathfrak{t}_{0.05} = `r qt(0.05, 34)`$.


## Valeurs-$p$

Si on applique la fonction de répartition de la loi nulle à la statistique, on obtient une valeur dans l'intervalle $[0,1]$.

La valeur-$p$ est la probabilité que la statistique de test soit égale ou plus extrême que la valeur calculée sur l'échantillon, si l'hypothèse nulle $\mathscr{H}_0$ est vraie


:::{.callout-caution}
L'[*American Statistical Association (ASA)* a publié une liste de principes](https://doi.org/10.1080/00031305.2016.1154108) détaillant les principales erreurs d'interprétation des valeurs-$p,$ notamment

- (2) Les valeurs-$p$ ne mesurent pas la probabilité que l'hypothèse étudiée est vrai
- (3) Les décisions d'affaires et scientiques ne devraient pas seulement être basées sur le fait qu'une valeur-$p$ est inférieure à un seuil spécifié.
- (5) Les valeurs-$p,$ ou la significativité statistiques, ne mesurent pas la taille de l'effet ou l'importance d'un résultat.

:::


## Analogie du procès

```{r}
#| label: fig-twelveangrymen
#| echo: false
#| out-width: '55%'
#| fig-cap: "Capture d'écran du drame _Douze hommes en colère_ (1957)"
knitr::include_graphics('fig/01/12_Angry_Men_scene.jpg')
```

## Analogie du procès 

La présomption d'innocence est de mise (on regarde tout comme si l'hypothèse nulle était vraie).

- On analyse toutes les preuves sous cette optique: est-ce que les preuves sont plausibles si la personne était innocente
- Le fardeau de la preuve revient à la poursuite, pour éviter les erreurs judiciaires (condamner une personne innocente).
- L'hypothèse nulle $\mathscr{H}_0$ est *non coupable*, contre l'alternative $\mathscr{H}_a$ *coupable*. 
- S'il y a un doute raisonnable, le verdict sera non coupable.

## À quoi s'attendre pour les valeurs-_$p$?

Si on répèt l'expérience avec des échantillons aléatoires simples, on s'attend à ce que les valeurs-$p$ soit uniformes si $\mathscr{H}_0$ est vraie **et** que la loi nulle est calibrée.

Sous l'alternative, les valeurs-$p$ auront tendance à être plus petites.


```{r}
#| label: fig-power-plots
#| echo: false
#| eval: true
#| cache: true
#| message: false
#| warning: false
#| fig-cap: "Densité empirique des valeurs-_p_ sous l'hypothèse nulle (gauche) et sous une alternative avec un rapport signal/bruit de 0.5 (droite)."
power_t <- function(x, ncp, df){dt(df = df, qt(p = x, df = df, ncp = ncp))/dt(df = df, qt(p = x, df = df))}
power_wald <- function(x, ncp){dnorm(qnorm(p = x, mean = ncp))/dnorm(qnorm(p = x))}
cdf_wald <- function(x, ncp){pnorm(qnorm(p = x, mean = ncp), lower.tail = TRUE)}
g1a <- ggplot() +
  geom_function(fun = power_t, args = list(ncp = 0, df = 5), xlim = c(0,1), n = 10001) +
  stat_function(fun = power_t, args = list(ncp = 0, df = 5),
                xlim = c(1e-12,0.1), geom = "area", fill = "blue", alpha = 0.2) +
  labs(y = "densité", x = "probabilité") +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0,5),
                     breaks = 1:5,
                     labels = 1:5)  +
  scale_x_continuous(expand = c(0,0),
                     limits = c(0,1),
                     breaks = sort(c(0.1, seq(0,1, by= 0.25))),
                     labels = c("0","0.1","0.25","0.5", "0.75", "1")) +
  theme_classic()

g3a <- ggplot() +
  geom_function(fun = power_wald, args = list(ncp = 0.5), xlim = c(0,1), n = 10001) +
  stat_function(fun = power_wald, args = list(ncp = 0.5),
                xlim = c(0,0.1), geom = "area", fill = 2, alpha = 0.2, n = 1001) +
  labs(y = "densité", x = "probabilité") +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0,5),
                     breaks = 1:5,
                     labels = 1:5)  +
  scale_x_continuous(expand = c(0,0),
                     limits = c(0,1),
                     breaks = sort(c(0.1, seq(0,1, by= 0.25))),
                     labels = c("0","0.1","0.25","0.5", "0.75", "1")) +
  theme_classic()
g1a + g3a
```

## Niveau du test


Si la loi $\mathscr{H}_0$ est vraie et que notre étalon de mesure est calibré, les valeurs-$p$ devraient suivre une loi uniforme

- Les petites valeurs-$p$ sont toujours possibles, mais rares si $p$ est faible.
- Puisque que l'on s'intéresse à l'alternative, on doit déterminer un **seuil de significativité** $\alpha$ pour savoir quand rejectter $\mathscr{H}_0$.


Pour prendre une décision, on compare notre valeur-$p$ $P$ avec le niveau du test $\alpha$:

- si $P < \alpha,$ on rejette $\mathscr{H}_0$;
- si $P \geq \alpha,$ on ne rejette pas $\mathscr{H}_0.$


La valeur fixe $\alpha \in (0, 1)$ est la probabilité de rejetter $\mathscr{H}_0$ quand cette dernière est vraie. 

## Erreurs statistiques


| **Décision** \\ **vrai modèle**   | $\mathscr{H}_0$ | $\mathscr{H}_a$ |
|:-- |:-: |:-: |
| ne pas rejeter $\mathscr{H}_0$ | $\checkmark$ | erreur de type II |
| rejeter $\mathscr{H}_0$ | erreur de type I | $\checkmark$|


On cherche à contrôler l'erreur de type I (soit rejetter $\mathscr{H}_0$ si $\mathscr{H}_0$ est vraie).

- analogie du procès: une erreur judiciaire, condamner un innocent

Puisque que l'on fixe le niveau $\alpha$, on n'a pas de contrôle sur l'erreur de type II

## Puissance

On aimerait être en mesure de détermine si $\mathscr{H}_0$ est fausse et, le cas échéant, rejetter cette hypothèse.

La **puissance** d'un test est la probabilité de rejeter $\mathscr{H}_0$ quand elle est fausse, soit
\begin{align*}
\Pr{\!}_a(\text{rejetter} \mathscr{H}_0),
\end{align*}
où $\Pr_a$ désigne la probabilité d'obtenir un résultat dans la zone de rejet pour une alternative **donnée**.

## Illustration du concept de puissance

```{r}
#| label: fig-puissance
#| cache: true
#| echo: false
#| fig-width: 10
#| fig-height: 3
#| out-width: '100%'
#| fig-cap: "Comparaison de la loi nulle (ligne pleine) et d'une alternative spécifique
#|   pour un test-$t$ (ligne traitillée). La puissance correspond à l'aire sous la courbe
#|   de la densité de la loi alternative qui est dans la zone de rejet du test (en blanc). Le panneau du milieu représente l'augmentation de la puissance suite à l'augmentation de la taille d'effet (différence moyenne entre groupes plus élevée) sous l'hypothèse alternative. Le panneau de droite correspond à un scénario alternatif avec la même taille d'effet, mais une taille d'échantillon ou une précision plus grande."
region <- data.frame(start = c(-Inf, qt(0.025, df = 10), qt(0.975, df = 10)),
                     end = c(qt(0.025, df = 10), qt(0.975, df = 10), Inf),
                     région = factor(c("rejeter","ne pas rejeter","rejeter")))
g1 <- ggplot(region) +
  geom_rect(aes(xmin = start, xmax = end, fill = région),
    ymin = -Inf, ymax = Inf, alpha = 0.2, data = region) +
  scale_fill_manual(values = c("blue","orange")) +
  coord_cartesian(xlim = c(-3.5,6), ylim = c(0, 1), expand = FALSE) +
  stat_function(fun = dt, args = list(ncp = 1.5, df=10), xlim = c(qt(0.975, df = 10), 10),
                geom = "area", fill = "white") +
  stat_function(fun = dt, n = 1000, args = list(df= 10), xlim = c(-5,6)) +
  stat_function(fun = dt, n = 1000, args = list(ncp = 1.5, df=10), lty = 2, xlim = c(-5,6)) +
  labs(y = "densité") +
  theme_classic() +
  theme(legend.position = "bottom")
region1 <- data.frame(start = c(-Inf, qnorm(0.025), qnorm(0.975)),
                     end = c(qnorm(0.025), qnorm(0.975), Inf),
                     région = factor(c("rejeter","ne pas rejeter","rejeter")))
g2 <- ggplot(region1) +
  geom_rect(aes(xmin = start, xmax = end, fill = région),
    ymin = -Inf, ymax = Inf, alpha = 0.2, data = region1) +
  scale_fill_manual(values = c("blue","orange")) +
  coord_cartesian(xlim = c(-3.5,5), ylim = c(0, 1), expand = FALSE) +
  stat_function(fun = dnorm, args = list(mean = 3, sd = 1), xlim = c(qnorm(0.975),10),
                geom = "area", fill = "white") +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), xlim = c(-5,5)) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 3, sd = 1), lty = 2, xlim = c(-5,5)) +
  labs(y = "densité") +
  theme_classic() +
  theme(legend.position = "bottom")
region2 <- data.frame(start = c(-Inf, qnorm(0.025, sd = 0.5), qnorm(0.975, sd = 0.5)),
                     end = c(qnorm(0.025, sd = 0.5), qnorm(0.975, sd = 0.5), Inf),
                     région = factor(c("rejeter","ne pas rejeter","rejeter")))
g3 <- ggplot(region) +
  geom_rect(aes(xmin = start, xmax = end, fill = région),
    ymin = -Inf, ymax = Inf, alpha = 0.2, data = region2) +
  scale_fill_manual(values = c("blue","orange")) +
  coord_cartesian(xlim = c(-3.5,5), ylim = c(0, 1), expand = FALSE) +
   stat_function(fun = dnorm, args = list(mean = 1.5, sd = 0.5), xlim = c(qnorm(0.975, sd = 0.5),10), geom = "area", fill = "white") +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 0, sd = 0.5), xlim = c(-5,5)) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = 1.5, sd = 0.5), lty = 2, xlim = c(-5,5)) +
  labs(y = "densité") +
  theme_classic() + theme(legend.position = "bottom")
g1 + g2 + g3 +
  patchwork::plot_layout(guides = 'collect')& theme(legend.position = "bottom")
```

## Critères qui déterminent la puissance


- la taille de l'effet: plus la différence est grande entre la valeur du paramètre postulée et le comportement observé, plus il est facile de le détecter;
- la variabilité: moins les observations sont variables, plus il est facile de déterminer que la différence observée est significative;
- la taille de l'échantillon: plus on a d'observations, plus petite est l'erreur-type
- le choix de la statistique de test


Minimalement, la puissance devrait être $\alpha$ puisqu'on rejette l'hypothèse nulle $\alpha$ du temps sous le scénario favorable où $\mathscr{H}_0$ est vraie. 

## Intervalle de confiance


Un **intervalle de confiance** est une façon alternative de présenter les conclusions d'un test d'hypothèse de niveau $\alpha$.

L'intervalle de confiance bilatéral de Wald $(1-\alpha)$ pour un paramètre unidimensionnel $\theta$ est
\begin{align*}
[\widehat{\theta} + \mathfrak{q}_{\alpha/2} \times \mathrm{se}(\widehat{\theta}), \widehat{\theta} +\mathfrak{q}_{1-\alpha/2}\times \mathrm{se}(\widehat{\theta})]
\end{align*}
soit l'estimation ponctuelle plus ou moins une marge d'erreur.

## Estimation: c'est pas du gâteau {.smaller}

On distingue entre notre objectif (estimand, par exemple la moyenne $\mu$), la recette ou formule (estimateur) et la sortie (estimé, une valeur numérique). 


```{r}
#| label: fig-cake
#| eval: true
#| echo: false
#| fig-cap: "Les concepts d'[estimand](https://www.flickr.com/photos/darkdwarf/16563489881) (gauche), estimateur (milieu) et [estimaté](https://www.flickr.com/photos/bensutherland/14685548773) (droite), illustrés à l'aide de gâteau, une variation d'un idée originale de Simon Grund. Les photos de gâteau sont partagées sous licence [CC BY-NC 2.0](https://creativecommons.org/licenses/by-nc/2.0/)."
#| fig-subcap:
#|  - "Estimand"
#|  - "Estimateurr"
#|  - "Estimé"
#| layout-ncol: 3
#| out-width: '90%'
knitr::include_graphics("fig/01/estimand.jpg")
knitr::include_graphics("fig/01/estimator.jpg")
knitr::include_graphics("fig/01/estimate.jpg")
```

## Interprétation d'un intervalle de confiance

Puisque les intrants de l'intervalle de confiance (l'estimateur) sont aléatoires, la sortie l'est également et change d'un échantillon à l'autre. Même si on répète une recette, on n'obtient pas toujours le même résultat.

- Si on calcule un intervalle de confiance pour un échantillon donné, la vraie valeur (inconnue) du paramètre $\theta$ est soit dans l'intervalle de confiance, soit pas: il n'y a pas de notion de probabilité!
- Le terme confiance s'applique à la *procédure* que l'on utilise pour calculer l'intervalle, et non pas dans les valeurs des bornes obtenues pour un échantillon en particulier.
- Si on répète l'expérience plusieurs fois, et qu'on calcule un intervalle de confiance de niveau $1-\alpha$ à chaque reprise, alors en moyenne une proportion de $1-\alpha$ des intervalles contiendra la vraie valeur de $\theta$ parmi toutes les répétitions.





## Propriétés fréquentistes des intervalles de confiance

```{r}
#| label: fig-intconf
#| eval: true
#| echo: false
#| cache: true
#| fig-width: 8
#| fig-height: 5
#| fig-cap: "Intervalles de confiance à 95% pour la moyenne d'une population normale standard pour 100 échantillons aléatoires. En moyenne, 5% de ces intervalles
#|   (en rouge) n'incluent pas la vraie valeur de la moyenne de zéro."
set.seed(1234)
interv <- t(sapply(1:100, function(i){t.test(rnorm(1000), mu=0)$conf.int}))
confint_dat <- data.frame(lower = interv[,1],
                          upper = interv[,2],
                          replicate = 1:100,
                          covers = factor((interv[,1] > 0) | (interv[,2] < 0), labels = c("couvre","ne couvre pas")))
confint_dat$covers <- relevel(confint_dat$covers, ref = "ne couvre pas")
ggplot(data = confint_dat,
       aes(x = factor(replicate))) +
  geom_hline(yintercept = 0) +
  geom_segment(mapping = aes(y = lower, yend = upper, x = replicate, xend = replicate, col = covers)) +
  # scale_color_discrete(c("black","red")) +
  labs(x = "no de l'étude de réplication",
       y = "",
       col = "") +
  theme_classic() +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank())
```


## Équivalence des intervalles de confiances et des valeurs-$p$

L'intervalle de confiance de niveau $1-\alpha$ nous donne la plage des valeurs pour lesquelles on ne peut rejetter $\mathscr{H}_0$ à niveau $\alpha$

- Règle de décision binaire avec intervalle de confiance: si la valeur postulée est dans l'intervalle, on ne rejette pas l'hypothèse nulle.
- La valeur-$p$ obtenue avec la même procédure satisferait $p \ge\alpha$ si on n'a pas rejetté avec l'intervalle de confiance (et vice-versa, $p <\alpha$ si la valeur postulée est hors de l'intervalle de confiance).

Les intervalles de confiance sont exprimés dans les mêmes unités que les données (donc plus interprétables?)

## 5. Obtenir une valeur-_p_ ou un intervalle de confiance

La valeur-_p_ est $p = \Pr_0(T > t_D)$, où $T \sim \mathsf{Student}(34)$. À l'aide de **R**, on obtient $p=0.0032$, inférieur à $\alpha=5$%.

```{r}
#| eval: true
#| echo: true
ttest$p.value
```

La borne inférieure de l'intervalle unilatéral est $\overline{D} + \mathsf{se}(\overline{D}) \times \mathfrak{t}_{0.05}$.

```{r}
#| eval: true
#| echo: true
ttest$conf.int
```

L'intervalle de confiance est $[`r as.numeric(ttest$conf.int)[1]`, \infty]$. La différence moyenne postulée, $0$, n'appartient pas à l'intervalle.


## **R** --- calculs à la mitaine

```{r}
#| label: distraction_manual
#| eval: true
#| echo: true
d <- with(distraction, t - c) # différence entre texter et conversation
n <- length(d) # taille de l'échantillon
(moy_d <- mean(d)) # différence moyenne
(errtype_d <- sd(d)/sqrt(n)) # erreur-type de la différence moyenne
(stat <- moy_d/errtype_d) # statistique du test-t
ddl <- n - 1L # degrés de liberté
crit <- qt(p = 0.05, df = ddl) # valeur critique, "q" pour quantiles
(valp <- pt(q = stat, df = ddl, lower.tail = FALSE)) # Pr(T > stat)
(ic_inf <- moy_d + errtype_d*crit) # borne inférieure de l'intervalle de confiance
```

::: aside

**R** utilise la convention `d/p/q/r` pour les fonctions de densité/répartition/quantile et pour la simulation. Le nom de la loi (par ex., `norm`, `t`, `chisq`, `f`, `unif`) suit cette lettre, donc

- `pnorm` est la fonction de répartition normale,
- `qt` est la fonction quantile d'une loi Student-$t$,
- `runif` génère des nombres aléatoires uniformes.
:::

## 6. Conclude in the setting of the problem



La différence moyenne estimée est de $`r ttest$estimate`$ secondes (écart-type de $`r sd(d)`$ secondes).  

On rejette $\mathscr{H}_0$: le temps de réaction est significativement plus élevé lorsqu'on texte que lorsqu'on parle au cellulaire en marchant. 

## Objectifs d'apprentissage


::: {.callout-note title="Objectifs d'apprentissage"}

* Comprendre le rôle de l’incertitude dans la prise de décision.
* Comprendre l’importance du rapport signal/bruit en tant que preuve.
* Connaître les ingrédients de base des tests d’hypothèse et être capable de formuler et d’identifier correctement ces composants dans un article scientifique
* Interpréter correctement les valeurs-$p$ et les intervalles de confiance pour un paramètre.

:::


## Références

